"""
Memory System Module
Copyright (c) 2025 Cristof Bano. All rights reserved.
Patent Pending
"""

from dataclasses import dataclass, field
from typing import Dict, List, Tuple, Optional, Set
from datetime import datetime
import numpy as np
from collections import defaultdict
import math
import json

@dataclass
class MemoryTrace:
    """Rappresenta una traccia di memoria con metadati"""
    content: str
    timestamp: datetime
    emotional_valence: float  # -1 to 1
    importance: float  # 0 to 1
    context: Dict = field(default_factory=dict)
    references: Set[str] = field(default_factory=set)
    recall_count: int = 0
    last_recall: Optional[datetime] = None
    categories: Set[str] = field(default_factory=set)
    strength: float = 1.0
    associations: Set[int] = field(default_factory=set)  # Collegamenti ad altre memorie
    patterns: Dict[str, float] = field(default_factory=dict)  # Pattern ricorrenti

class MemorySystem:
    """Sistema di memoria principale che integra diversi tipi di memoria"""
    
    def __init__(self):
        self.memories = []
        self.episodic = EpisodicMemory()
        self.semantic = SemanticMemory()
        self.procedural = ProceduralMemory()
        self.enhanced = EnhancedMemorySystem()
        
    def add_memory(self, content: str, emotional_valence: float = 0.0, context: Dict = None) -> None:
        """Aggiunge una nuova memoria al sistema"""
        self.episodic.add_memory(content, emotional_valence, context)
        
    def add_interaction(self, input_text: str, output_text: str) -> None:
        """Aggiunge una nuova interazione alla memoria"""
        self.memories.append({
            "input": input_text,
            "output": output_text,
            "timestamp": datetime.now()
        })
        
    def recall(self, query: str, context: Dict = None) -> List[MemoryTrace]:
        """Recupera memorie rilevanti"""
        return self.enhanced.recall_memory(query, context)
        
    def consolidate(self) -> None:
        """Consolida le memorie e rafforza le connessioni"""
        self.episodic._consolidate_memories()
        
    def save_state(self, filename: str) -> None:
        """Salva lo stato del sistema di memoria"""
        self.enhanced.save_to_file(filename)
        
    def load_state(self, filename: str) -> None:
        """Carica lo stato del sistema di memoria"""
        self.enhanced.load_from_file(filename)

@dataclass
class EpisodicMemory:
    """Gestisce i ricordi di eventi specifici e esperienze personali"""
    memories: List[MemoryTrace] = field(default_factory=list)
    max_size: int = 1000
    categories: Dict[str, Set[int]] = field(default_factory=lambda: defaultdict(set))
    last_consolidation: datetime = field(default_factory=datetime.now)
    association_strength: Dict[Tuple[int, int], float] = field(default_factory=dict)
    pattern_threshold: float = 0.3  # Abbassata la soglia per i pattern

    def add_memory(self, content: str, emotional_valence: float, context: Dict = None) -> None:
        """Aggiunge un nuovo ricordo episodico"""
        importance = self._calculate_importance(emotional_valence, context)
        categories = self._extract_categories(content, context)

        # Crea la nuova memoria
        memory = MemoryTrace(
            content=content,
            timestamp=datetime.now(),
            emotional_valence=emotional_valence,
            importance=importance,
            context=context or {},
            categories=categories
        )

        # Trova pattern e associazioni
        self._find_patterns(memory)
        self._create_associations(memory)

        # Aggiunge la memoria
        self.memories.append(memory)

        # Aggiorna le categorie
        for category in categories:
            self.categories[category].add(len(self.memories) - 1)

        # Consolida se necessario
        self._check_consolidation()
        
    def _calculate_importance(self, emotional_valence: float, context: Optional[Dict]) -> float:
        """Calcola l'importanza di una memoria"""
        importance = abs(emotional_valence)  # Base importance from emotion
        
        if context:
            # Add importance from context
            if 'urgency' in context:
                importance += context['urgency'] * 0.3
            if 'relevance' in context:
                importance += context['relevance'] * 0.3
                
        return min(1.0, importance)  # Cap at 1.0
        
    def _extract_categories(self, content: str, context: Optional[Dict]) -> Set[str]:
        """Estrae le categorie da contenuto e contesto"""
        categories = set()
        
        # Add basic categories
        if 'emotion' in context:
            categories.add(f"emotion_{context['emotion']}")
        if 'topic' in context:
            categories.add(f"topic_{context['topic']}")
            
        return categories
        
    def _find_patterns(self, memory: MemoryTrace) -> None:
        """Trova pattern ricorrenti nella memoria"""
        # Simple pattern matching for now
        words = set(memory.content.lower().split())
        for other in self.memories[-10:]:  # Look at recent memories
            other_words = set(other.content.lower().split())
            similarity = len(words & other_words) / len(words | other_words)
            if similarity > self.pattern_threshold:
                pattern = " ".join(words & other_words)
                memory.patterns[pattern] = similarity
                
    def _create_associations(self, memory: MemoryTrace) -> None:
        """Crea associazioni con altre memorie"""
        current_idx = len(self.memories)
        
        for i, other in enumerate(self.memories[-10:]):
            # Create association based on shared categories and patterns
            shared_categories = len(memory.categories & other.categories)
            shared_patterns = len(set(memory.patterns) & set(other.patterns))
            
            if shared_categories > 0 or shared_patterns > 0:
                strength = (shared_categories * 0.6 + shared_patterns * 0.4) / \
                          (len(memory.categories) + len(memory.patterns))
                
                if strength > 0.2:  # Threshold for creating association
                    memory.associations.add(i)
                    other.associations.add(current_idx)
                    self.association_strength[(current_idx, i)] = strength
                    
    def _check_consolidation(self) -> None:
        """Verifica se è necessario consolidare le memorie"""
        if (datetime.now() - self.last_consolidation).total_seconds() > 3600:  # 1 hour
            self._consolidate_memories()
            
    def _consolidate_memories(self) -> None:
        """Consolida le memorie rafforzando o indebolendo collegamenti"""
        self.last_consolidation = datetime.now()
        
        # Update memory strengths
        for memory in self.memories:
            time_factor = math.exp(-0.1 * (datetime.now() - memory.timestamp).days)
            recall_factor = math.log(memory.recall_count + 1)
            memory.strength = min(1.0, memory.strength * time_factor * (1 + 0.1 * recall_factor))
            
        # Update association strengths
        for (i, j), strength in self.association_strength.items():
            if i < len(self.memories) and j < len(self.memories):
                memory_i = self.memories[i]
                memory_j = self.memories[j]
                
                # Strengthen if both memories are strong
                new_strength = strength * math.sqrt(memory_i.strength * memory_j.strength)
                self.association_strength[(i, j)] = new_strength

class SemanticMemory:
    """Gestisce la conoscenza concettuale e fattuale"""
    concepts: Dict[str, Dict] = field(default_factory=lambda: defaultdict(dict))
    relationships: Dict[str, Set[Tuple[str, str]]] = field(default_factory=lambda: defaultdict(set))
    
    def add_concept(self, concept: str, attributes: Dict) -> None:
        """Aggiunge o aggiorna un concetto"""
        self.concepts[concept].update(attributes)
        
    def add_relationship(self, concept1: str, relation: str, concept2: str) -> None:
        """Aggiunge una relazione tra concetti"""
        self.relationships[relation].add((concept1, concept2))
        
    def get_related_concepts(self, concept: str) -> Set[str]:
        """Trova concetti correlati"""
        related = set()
        for relation, pairs in self.relationships.items():
            for c1, c2 in pairs:
                if c1 == concept:
                    related.add(c2)
                elif c2 == concept:
                    related.add(c1)
        return related
        
    def query_knowledge(self, query: str) -> Dict:
        """Interroga la base di conoscenza"""
        # Simplified query processing
        if query in self.concepts:
            return self.concepts[query]
        return {}

class ProceduralMemory:
    """Gestisce la memoria delle procedure e abilità"""
    procedures: Dict[str, Dict] = field(default_factory=dict)
    
    def add_procedure(self, name: str, steps: List[str], context: Dict = None) -> None:
        """Aggiunge una nuova procedura"""
        self.procedures[name] = {
            'steps': steps,
            'mastery': 0.0,
            'practice_count': 0,
            'context': context or {},
            'last_practice': None
        }
        
    def practice_procedure(self, name: str, success_rate: float) -> None:
        """Registra la pratica di una procedura"""
        if name in self.procedures:
            proc = self.procedures[name]
            proc['practice_count'] += 1
            proc['mastery'] = (proc['mastery'] * 0.7 + success_rate * 0.3)
            proc['last_practice'] = datetime.now()
            
    def get_procedure(self, name: str) -> Optional[Dict]:
        """Recupera una procedura"""
        return self.procedures.get(name)
        
    def get_mastery_level(self, name: str) -> float:
        """Ottiene il livello di maestria di una procedura"""
        if name in self.procedures:
            return self.procedures[name]['mastery']
        return 0.0

class Memory:
    def __init__(self, short_term_size: int = 100, long_term_size: int = 1000):
        """
        Inizializza il sistema di memoria

        Args:
            short_term_size: Dimensione massima della memoria a breve termine
            long_term_size: Dimensione massima della memoria a lungo termine
        """
        self.short_term = []
        self.long_term = []
        self.short_term_size = short_term_size
        self.long_term_size = long_term_size
        self.total_interactions = 0
        
    def add_interaction(self, input_text: str, output_text: str) -> None:
        """Aggiunge un'interazione alla memoria"""
        interaction = {
            'input': input_text,
            'output': output_text,
            'timestamp': datetime.now(),
            'id': self.total_interactions
        }
        
        self.short_term.append(interaction)
        self.total_interactions += 1
        
        if len(self.short_term) > self.short_term_size:
            self._consolidate_memory()
            
    def get_recent_interactions(self, n: int = 3) -> List[Dict]:
        """Ottiene le n interazioni più recenti"""
        return sorted(
            self.short_term,
            key=lambda x: x['timestamp'],
            reverse=True
        )[:n]
        
    def search_similar(self, query: str, n: int = 3) -> List[Dict]:
        """Cerca interazioni simili nella memoria"""
        # Simplified similarity search
        results = []
        for memory in self.short_term + self.long_term:
            similarity = self._calculate_similarity(query, memory['input'])
            if similarity > 0.3:  # Threshold
                results.append((similarity, memory))
                
        return [m for _, m in sorted(results, reverse=True)][:n]
        
    def _calculate_similarity(self, text1: str, text2: str) -> float:
        """Calcola la similarità tra due testi"""
        # Simple word overlap similarity
        words1 = set(text1.lower().split())
        words2 = set(text2.lower().split())
        
        if not words1 or not words2:
            return 0.0
            
        return len(words1 & words2) / len(words1 | words2)
        
    def _consolidate_memory(self) -> None:
        """Consolida la memoria spostando elementi dalla STM alla LTM"""
        while len(self.short_term) > self.short_term_size:
            # Move oldest items to long-term memory
            oldest = min(self.short_term, key=lambda x: x['timestamp'])
            self.short_term.remove(oldest)
            
            if len(self.long_term) < self.long_term_size:
                self.long_term.append(oldest)
            else:
                # Replace least important memory
                least_important = min(
                    self.long_term,
                    key=lambda x: self._calculate_importance(x)
                )
                idx = self.long_term.index(least_important)
                self.long_term[idx] = oldest
                
    def _calculate_importance(self, memory: Dict) -> float:
        """Calcola l'importanza di una memoria"""
        # Simple importance calculation
        age = (datetime.now() - memory['timestamp']).total_seconds()
        recency = math.exp(-age / (24 * 3600))  # Decay over 24 hours
        
        # Could be extended with more factors
        return recency

class EnhancedMemorySystem:
    """Sistema di memoria potenziato che integra i diversi tipi di memoria"""
    
    def __init__(self):
        self.episodic = EpisodicMemory()
        self.semantic = SemanticMemory()
        self.procedural = ProceduralMemory()
        
    def process_experience(self, content: str, emotional_valence: float, 
                         context: Dict = None, extract_knowledge: bool = True) -> None:
        """Elabora una nuova esperienza"""
        # Add to episodic memory
        self.episodic.add_memory(content, emotional_valence, context)
        
        if extract_knowledge:
            self._extract_concepts(content, context)
            
    def _extract_concepts(self, content: str, context: Optional[Dict]) -> None:
        """Estrae concetti dal contenuto e li memorizza"""
        # Simple concept extraction
        words = content.lower().split()
        for word in words:
            if len(word) > 3:  # Skip short words
                attributes = {'frequency': self.semantic.concepts.get(word, {}).get('frequency', 0) + 1}
                if context:
                    attributes.update(context)
                self.semantic.add_concept(word, attributes)
                
    def recall_memory(self, query: str, context: Optional[Dict] = None) -> List[MemoryTrace]:
        """Recupera memorie rilevanti da tutti i sistemi"""
        memories = []
        
        # Search episodic memories
        for memory in self.episodic.memories:
            if query.lower() in memory.content.lower():
                memories.append(memory)
                
        # Could be extended with semantic and procedural memory
        return sorted(memories, key=lambda x: x.importance, reverse=True)
        
    def save_to_file(self, filename: str) -> None:
        """Salva lo stato del sistema di memoria su file"""
        state = {
            'episodic': [vars(m) for m in self.episodic.memories],
            'semantic': {
                'concepts': dict(self.semantic.concepts),
                'relationships': {k: list(v) for k, v in self.semantic.relationships.items()}
            },
            'procedural': dict(self.procedural.procedures)
        }
        
        with open(filename, 'w') as f:
            json.dump(state, f)
            
    def load_from_file(self, filename: str) -> None:
        """Carica lo stato del sistema di memoria da file"""
        with open(filename, 'r') as f:
            state = json.load(f)
            
        # Restore episodic memories
        self.episodic.memories = []
        for m in state['episodic']:
            memory = MemoryTrace(**m)
            self.episodic.memories.append(memory)
            
        # Restore semantic memory
        self.semantic.concepts = defaultdict(dict, state['semantic']['concepts'])
        self.semantic.relationships = defaultdict(set)
        for k, v in state['semantic']['relationships'].items():
            self.semantic.relationships[k] = set(tuple(x) for x in v)
            
        # Restore procedural memory
        self.procedural.procedures = state['procedural']
